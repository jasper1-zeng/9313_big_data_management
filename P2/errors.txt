[user@sahara ~]$ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
24/10/20 15:58:52 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1, but we could
n't find any external IP address!
24/10/20 15:58:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/10/20 15:58:53 INFO SparkContext: Running Spark version 3.5.0
24/10/20 15:58:53 INFO SparkContext: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 15:58:53 INFO SparkContext: Java version 1.8.0_412
24/10/20 15:58:53 INFO ResourceUtils: ==============================================================
24/10/20 15:58:53 INFO ResourceUtils: No custom resources configured for spark.driver.
24/10/20 15:58:53 INFO ResourceUtils: ==============================================================
24/10/20 15:58:53 INFO SparkContext: Submitted application: project2_rdd
24/10/20 15:58:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amo
unt: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0,
 script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/10/20 15:58:53 INFO ResourceProfile: Limiting resource is cpu
24/10/20 15:58:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/10/20 15:58:53 INFO SecurityManager: Changing view acls to: user
24/10/20 15:58:53 INFO SecurityManager: Changing modify acls to: user
24/10/20 15:58:53 INFO SecurityManager: Changing view acls groups to: 
24/10/20 15:58:53 INFO SecurityManager: Changing modify acls groups to: 
24/10/20 15:58:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permis
sions: user; groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMP
TY
24/10/20 15:58:54 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random 
bytes: c6:28:8c:82:37:13:03:35
24/10/20 15:58:54 INFO Utils: Successfully started service 'sparkDriver' on port 34683.
24/10/20 15:58:54 INFO SparkEnv: Registering MapOutputTracker
24/10/20 15:58:54 INFO SparkEnv: Registering BlockManagerMaster
24/10/20 15:58:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topolo
gy information
24/10/20 15:58:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/10/20 15:58:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/10/20 15:58:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c53bb941-77db-4bb6-ac40-0cdfa35ac0ca
24/10/20 15:58:54 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/10/20 15:58:54 INFO SparkEnv: Registering OutputCommitCoordinator
24/10/20 15:58:54 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/10/20 15:58:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/10/20 15:58:54 INFO Executor: Starting executor ID driver on host localhost.localdomain
24/10/20 15:58:54 INFO Executor: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 15:58:54 INFO Executor: Java version 1.8.0_412
24/10/20 15:58:54 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/10/20 15:58:54 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@61e947e0
 for default.
24/10/20 15:58:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on p
ort 32855.
24/10/20 15:58:54 INFO NettyBlockTransferService: Server created on localhost.localdomain:32855
24/10/20 15:58:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication pol
icy
24/10/20 15:58:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost.localdomain, 32855, N
one)
24/10/20 15:58:54 INFO BlockManagerMasterEndpoint: Registering block manager localhost.localdomain:32855 with 366.3 MiB RA
M, BlockManagerId(driver, localhost.localdomain, 32855, None)
24/10/20 15:58:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost.localdomain, 32855, No
ne)
24/10/20 15:58:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost.localdomain, 32855, None)
24/10/20 15:58:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 362.3 KiB, free 365.9 MiB
)
24/10/20 15:58:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 365.
9 MiB)
24/10/20 15:58:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost.localdomain:32855 (size: 33.0 KiB
, free: 366.3 MiB)
24/10/20 15:58:55 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/10/20 15:58:55 INFO FileInputFormat: Total input files to process : 1
24/10/20 15:58:55 INFO SparkContext: Starting job: collectAsMap at /home/project2_rdd.py:43
24/10/20 15:58:55 INFO DAGScheduler: Registering RDD 4 (reduceByKey at /home/project2_rdd.py:43) as input to shuffle 0
24/10/20 15:58:55 INFO DAGScheduler: Got job 0 (collectAsMap at /home/project2_rdd.py:43) with 1 output partitions
24/10/20 15:58:55 INFO DAGScheduler: Final stage: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43)
24/10/20 15:58:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
24/10/20 15:58:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
24/10/20 15:58:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:
43), which has no missing parents
24/10/20 15:58:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.9 MiB)
24/10/20 15:58:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.9
 MiB)
24/10/20 15:58:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost.localdomain:32855 (size: 8.8 KiB,
 free: 366.3 MiB)
24/10/20 15:58:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /
home/project2_rdd.py:43) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/10/20 15:58:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost.localdomain, executor driver, par
tition 0, PROCESS_LOCAL, 7642 bytes) 
24/10/20 15:58:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/10/20 15:58:55 INFO HadoopRDD: Input split: file:/home/abcnews.txt:0+616
24/10/20 15:58:56 INFO PythonRunner: Times: total = 550, boot = 470, init = 79, finish = 1
24/10/20 15:58:56 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 603.0 B, free 365.9 MiB)
24/10/20 15:58:56 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost.localdomain:32855 (size: 603.0 B, free: 366.
3 MiB)
24/10/20 15:58:56 INFO PythonRunner: Times: total = 43, boot = -110, init = 153, finish = 0
24/10/20 15:58:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1675 bytes result sent to driver
24/10/20 15:58:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1035 ms on localhost.localdomain (executo
r driver) (1/1)
24/10/20 15:58:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/10/20 15:58:56 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 45405
24/10/20 15:58:56 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/project2_rdd.py:43) finished in 1.108 s
24/10/20 15:58:56 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:56 INFO DAGScheduler: running: Set()
24/10/20 15:58:56 INFO DAGScheduler: waiting: Set(ResultStage 1)
24/10/20 15:58:56 INFO DAGScheduler: failed: Set()
24/10/20 15:58:56 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43), 
which has no missing parents
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 365.9 MiB)
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9
 MiB)
24/10/20 15:58:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost.localdomain:32855 (size: 6.0 KiB,
 free: 366.3 MiB)
24/10/20 15:58:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at collectAsMap at /home/
project2_rdd.py:43) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/10/20 15:58:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost.localdomain, executor driver, par
tition 0, NODE_LOCAL, 7433 bytes) 
24/10/20 15:58:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/10/20 15:58:56 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (
0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/10/20 15:58:56 INFO PythonRunner: Times: total = 42, boot = -125, init = 167, finish = 0
24/10/20 15:58:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2111 bytes result sent to driver
24/10/20 15:58:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 97 ms on localhost.localdomain (executor 
driver) (1/1)
24/10/20 15:58:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/10/20 15:58:56 INFO DAGScheduler: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43) finished in 0.111 s
24/10/20 15:58:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 15:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/10/20 15:58:56 INFO DAGScheduler: Job 0 finished: collectAsMap at /home/project2_rdd.py:43, took 1.300573 s
24/10/20 15:58:56 INFO SparkContext: Starting job: collect at /home/project2_rdd.py:49
24/10/20 15:58:56 INFO DAGScheduler: Registering RDD 9 (reduceByKey at /home/project2_rdd.py:48) as input to shuffle 1
24/10/20 15:58:56 INFO DAGScheduler: Got job 1 (collect at /home/project2_rdd.py:49) with 1 output partitions
24/10/20 15:58:56 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/project2_rdd.py:49)
24/10/20 15:58:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
24/10/20 15:58:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
24/10/20 15:58:56 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:
48), which has no missing parents
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.5 KiB, free 365.9 MiB)
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8
 MiB)
24/10/20 15:58:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost.localdomain:32855 (size: 9.1 KiB,
 free: 366.2 MiB)
24/10/20 15:58:56 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /
home/project2_rdd.py:48) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/10/20 15:58:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost.localdomain, executor driver, par
tition 0, PROCESS_LOCAL, 7642 bytes) 
24/10/20 15:58:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/10/20 15:58:56 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 15:58:56 INFO PythonRunner: Times: total = 58, boot = -43, init = 101, finish = 0
24/10/20 15:58:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1589 bytes result sent to driver
24/10/20 15:58:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on localhost.localdomain (executor 
driver) (1/1)
24/10/20 15:58:56 INFO DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/project2_rdd.py:48) finished in 0.087 s
24/10/20 15:58:56 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:56 INFO DAGScheduler: running: Set()
24/10/20 15:58:56 INFO DAGScheduler: waiting: Set(ResultStage 3)
24/10/20 15:58:56 INFO DAGScheduler: failed: Set()
24/10/20 15:58:56 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49), whic
h has no missing parents
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 365.8 MiB)
24/10/20 15:58:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/10/20 15:58:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.8
 MiB)
24/10/20 15:58:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost.localdomain:32855 (size: 6.0 KiB,
 free: 366.2 MiB)
24/10/20 15:58:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[12] at collect at /home/proj
ect2_rdd.py:49) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:56 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/10/20 15:58:56 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost.localdomain, executor driver, par
tition 0, NODE_LOCAL, 7433 bytes) 
24/10/20 15:58:56 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/10/20 15:58:56 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/10/20 15:58:56 INFO PythonRunner: Times: total = 44, boot = -27, init = 71, finish = 0
24/10/20 15:58:56 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2973 bytes result sent to driver
24/10/20 15:58:56 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 68 ms on localhost.localdomain (executor 
driver) (1/1)
24/10/20 15:58:56 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/10/20 15:58:56 INFO DAGScheduler: ResultStage 3 (collect at /home/project2_rdd.py:49) finished in 0.075 s
24/10/20 15:58:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 15:58:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/10/20 15:58:56 INFO DAGScheduler: Job 1 finished: collect at /home/project2_rdd.py:49, took 0.168298 s
24/10/20 15:58:57 INFO SparkContext: Starting job: takeOrdered at /home/project2_rdd.py:80
24/10/20 15:58:57 INFO DAGScheduler: Registering RDD 14 (reduceByKey at /home/project2_rdd.py:57) as input to shuffle 5
24/10/20 15:58:57 INFO DAGScheduler: Registering RDD 18 (reduceByKey at /home/project2_rdd.py:64) as input to shuffle 4
24/10/20 15:58:57 INFO DAGScheduler: Registering RDD 25 (join at /home/project2_rdd.py:70) as input to shuffle 3
24/10/20 15:58:57 INFO DAGScheduler: Registering RDD 29 (reduceByKey at /home/project2_rdd.py:75) as input to shuffle 2
24/10/20 15:58:57 INFO DAGScheduler: Got job 2 (takeOrdered at /home/project2_rdd.py:80) with 2 output partitions
24/10/20 15:58:57 INFO DAGScheduler: Final stage: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80)
24/10/20 15:58:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
24/10/20 15:58:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
24/10/20 15:58:57 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py
:57), which has no missing parents
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8
 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost.localdomain:32855 (size: 9.1 KiB,
 free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at 
/home/project2_rdd.py:57) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/10/20 15:58:57 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py
:64), which has no missing parents
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost.localdomain, executor driver, par
tition 0, PROCESS_LOCAL, 7642 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/10/20 15:58:57 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8
 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost.localdomain:32855 (size: 9.1 KiB,
 free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at 
/home/project2_rdd.py:64) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/10/20 15:58:57 INFO PythonRunner: Times: total = 52, boot = -78, init = 130, finish = 0
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1589 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (localhost.localdomain, executor driver, par
tition 0, PROCESS_LOCAL, 7642 bytes) 
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 69 ms on localhost.localdomain (executor 
driver) (1/1)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/10/20 15:58:57 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/project2_rdd.py:57) finished in 0.078 s
24/10/20 15:58:57 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:57 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
24/10/20 15:58:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 15:58:57 INFO DAGScheduler: failed: Set()
24/10/20 15:58:57 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 15:58:57 INFO PythonRunner: Times: total = 48, boot = -10, init = 57, finish = 1
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1589 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 61 ms on localhost.localdomain (executor 
driver) (1/1)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at /home/project2_rdd.py:64) finished in 0.130 s
24/10/20 15:58:57 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:57 INFO DAGScheduler: running: Set()
24/10/20 15:58:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 15:58:57 INFO DAGScheduler: failed: Set()
24/10/20 15:58:57 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70), w
hich has no missing parents
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.0 KiB, free 365.8 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.8
 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost.localdomain:32855 (size: 9.7 KiB,
 free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/p
roject2_rdd.py:70) (first 15 tasks are for partitions Vector(0, 1))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (localhost.localdomain, executor driver, par
tition 0, NODE_LOCAL, 7531 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 44, boot = -21, init = 65, finish = 0
24/10/20 15:58:57 INFO PythonRunner: Times: total = 86, boot = 10, init = 75, finish = 1
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2235 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (localhost.localdomain, executor driver, par
tition 1, NODE_LOCAL, 7531 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 109 ms on localhost.localdomain (executor
 driver) (1/2)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 48, boot = -56, init = 104, finish = 0
24/10/20 15:58:57 INFO PythonRunner: Times: total = 45, boot = -24, init = 68, finish = 1
24/10/20 15:58:57 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 2235 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 83 ms on localhost.localdomain (executor 
driver) (2/2)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO DAGScheduler: ShuffleMapStage 6 (join at /home/project2_rdd.py:70) finished in 0.198 s
24/10/20 15:58:57 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:57 INFO DAGScheduler: running: Set()
24/10/20 15:58:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/10/20 15:58:57 INFO DAGScheduler: failed: Set()
24/10/20 15:58:57 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py
:75), which has no missing parents
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 365.7 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 365.7
 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost.localdomain:32855 (size: 9.6 KiB,
 free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at 
/home/project2_rdd.py:75) (first 15 tasks are for partitions Vector(0, 1))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (localhost.localdomain, executor driver, par
tition 0, NODE_LOCAL, 7422 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 (980.0 B) non-empty blocks including 2 (980.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 42, boot = -30, init = 71, finish = 1
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (localhost.localdomain, executor driver, par
tition 1, NODE_LOCAL, 7422 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 60 ms on localhost.localdomain (executor 
driver) (1/2)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 (1245.0 B) non-empty blocks including 2 (1245.0 B) local and
 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 50, boot = -79, init = 129, finish = 0
24/10/20 15:58:57 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 2235 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 71 ms on localhost.localdomain (executor 
driver) (2/2)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at /home/project2_rdd.py:75) finished in 0.138 s
24/10/20 15:58:57 INFO DAGScheduler: looking for newly runnable stages
24/10/20 15:58:57 INFO DAGScheduler: running: Set()
24/10/20 15:58:57 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/10/20 15:58:57 INFO DAGScheduler: failed: Set()
24/10/20 15:58:57 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80), 
which has no missing parents
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.2 KiB, free 365.7 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.7
 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost.localdomain:32855 (size: 7.4 KiB,
 free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[32] at takeOrdered at /home/
project2_rdd.py:80) (first 15 tasks are for partitions Vector(0, 1))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (localhost.localdomain, executor driver, pa
rtition 0, NODE_LOCAL, 7433 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 (532.0 B) non-empty blocks including 2 (532.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 42, boot = -90, init = 132, finish = 0
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2168 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (localhost.localdomain, executor driver, pa
rtition 1, NODE_LOCAL, 7433 bytes) 
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 52 ms on localhost.localdomain (executor
 driver) (1/2)
24/10/20 15:58:57 INFO Executor: Running task 1.0 in stage 8.0 (TID 11)
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Getting 2 (490.0 B) non-empty blocks including 2 (490.0 B) local and 0
 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 15:58:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 15:58:57 INFO PythonRunner: Times: total = 43, boot = -76, init = 119, finish = 0
24/10/20 15:58:57 INFO Executor: Finished task 1.0 in stage 8.0 (TID 11). 2240 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 76 ms on localhost.localdomain (executor
 driver) (2/2)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO DAGScheduler: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80) finished in 0.133 s
24/10/20 15:58:57 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 15:58:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/10/20 15:58:57 INFO DAGScheduler: Job 2 finished: takeOrdered at /home/project2_rdd.py:80, took 0.618000 s
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost.localdomain:32855 in memory (size: 9.1 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.output
dir
24/10/20 15:58:57 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitt
er
24/10/20 15:58:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost.localdomain:32855 in memory (size: 6.0 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:fal
se, ignore cleanup failures: false
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost.localdomain:32855 in memory (size: 6.0 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost.localdomain:32855 in memory (size: 9.6 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
24/10/20 15:58:57 INFO DAGScheduler: Got job 3 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
24/10/20 15:58:57 INFO DAGScheduler: Final stage: ResultStage 9 (runJob at SparkHadoopWriter.scala:83)
24/10/20 15:58:57 INFO DAGScheduler: Parents of final stage: List()
24/10/20 15:58:57 INFO DAGScheduler: Missing parents: List()
24/10/20 15:58:57 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at saveAsTextFile at NativeMethodAcces
sorImpl.java:0), which has no missing parents
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost.localdomain:32855 in memory (size: 8.8 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 106.9 KiB, free 365.7 Mi
B)
24/10/20 15:58:57 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 39.9 KiB, free 365
.7 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost.localdomain:32855 (size: 39.9 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
24/10/20 15:58:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at saveAsTextFile
 at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/10/20 15:58:57 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/10/20 15:58:57 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12) (localhost.localdomain, executor driver, pa
rtition 0, PROCESS_LOCAL, 7972 bytes) 
24/10/20 15:58:57 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost.localdomain:32855 in memory (size: 9.7 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitt
er
24/10/20 15:58:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/10/20 15:58:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:fal
se, ignore cleanup failures: false
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost.localdomain:32855 in memory (size: 9.1 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost.localdomain:32855 in memory (size: 9.1 Ki
B, free: 366.2 MiB)
24/10/20 15:58:57 INFO PythonRunner: Times: total = 84, boot = -178, init = 262, finish = 0
24/10/20 15:58:57 INFO PythonRunner: Times: total = 89, boot = -235, init = 324, finish = 0
24/10/20 15:58:57 INFO FileOutputCommitter: Saved output of task 'attempt_202410201558572281296262885134423_0038_m_000000_
0' to file:/home/output/_temporary/0/task_202410201558572281296262885134423_0038_m_000000
24/10/20 15:58:57 INFO SparkHadoopMapRedUtil: attempt_202410201558572281296262885134423_0038_m_000000_0: Committed. Elapse
24/10/20 15:58:57 INFO PythonRunner: Times: total = 89, boot = -235, init = 324, finish = 0
24/10/20 15:58:57 INFO FileOutputCommitter: Saved output of task 'attempt_202410201558572281296262885134423_0038_m_000000_0' to file:/home/output/_temporar
y/0/task_202410201558572281296262885134423_0038_m_000000
24/10/20 15:58:57 INFO SparkHadoopMapRedUtil: attempt_202410201558572281296262885134423_0038_m_000000_0: Committed. Elapsed time: 1 ms.
24/10/20 15:58:57 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 1620 bytes result sent to driver
24/10/20 15:58:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 153 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 15:58:57 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/10/20 15:58:57 INFO DAGScheduler: ResultStage 9 (runJob at SparkHadoopWriter.scala:83) finished in 0.171 s
24/10/20 15:58:57 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 15:58:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/10/20 15:58:57 INFO DAGScheduler: Job 3 finished: runJob at SparkHadoopWriter.scala:83, took 0.180229 s
24/10/20 15:58:57 INFO SparkHadoopWriter: Start to commit write Job job_202410201558572281296262885134423_0038.
24/10/20 15:58:57 INFO SparkHadoopWriter: Write Job job_202410201558572281296262885134423_0038 committed. Elapsed time: 13 ms.
24/10/20 15:58:57 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/10/20 15:58:57 INFO SparkUI: Stopped Spark web UI at http://localhost.localdomain:4040
24/10/20 15:58:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/10/20 15:58:58 INFO MemoryStore: MemoryStore cleared
24/10/20 15:58:58 INFO BlockManager: BlockManager stopped
24/10/20 15:58:58 INFO BlockManagerMaster: BlockManagerMaster stopped
24/10/20 15:58:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/10/20 15:58:58 INFO SparkContext: Successfully stopped SparkContext
24/10/20 15:58:58 INFO ShutdownHookManager: Shutdown hook called
24/10/20 15:58:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-342808f3-d228-493d-a1c5-f8abdcb35208
24/10/20 15:58:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-4bf697f6-07f0-4754-87e6-d11f0454ae95/pyspark-c15b3b54-8232-42e3-8cc8-e581e973a3a0
24/10/20 15:58:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-4bf697f6-07f0-4754-87e6-d11f0454ae95
[user@sahara ~]$ cat home/output/part-*
cat: 'home/output/part-*': No such file or directory
[user@sahara ~]$ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
24/10/20 16:01:00 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!
24/10/20 16:01:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/10/20 16:01:01 INFO SparkContext: Running Spark version 3.5.0
24/10/20 16:01:01 INFO SparkContext: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:01:01 INFO SparkContext: Java version 1.8.0_412
24/10/20 16:01:01 INFO ResourceUtils: ==============================================================
24/10/20 16:01:01 INFO ResourceUtils: No custom resources configured for spark.driver.
24/10/20 16:01:01 INFO ResourceUtils: ==============================================================
24/10/20 16:01:01 INFO SparkContext: Submitted application: project2_rdd
24/10/20 16:01:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memor
y -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amou
nt: 1.0)
24/10/20 16:01:01 INFO ResourceProfile: Limiting resource is cpu
24/10/20 16:01:01 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/10/20 16:01:01 INFO SecurityManager: Changing view acls to: user
24/10/20 16:01:01 INFO SecurityManager: Changing modify acls to: user
24/10/20 16:01:01 INFO SecurityManager: Changing view acls groups to: 
24/10/20 16:01:01 INFO SecurityManager: Changing modify acls groups to: 
24/10/20 16:01:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user; groups with view per
missions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY
24/10/20 16:01:01 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: af:46:02:55:d2:eb:0c:6c
24/10/20 16:01:01 INFO Utils: Successfully started service 'sparkDriver' on port 37479.
24/10/20 16:01:01 INFO SparkEnv: Registering MapOutputTracker
24/10/20 16:01:01 INFO SparkEnv: Registering BlockManagerMaster
24/10/20 16:01:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/10/20 16:01:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/10/20 16:01:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/10/20 16:01:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-969deb81-ce80-4b08-9b17-b533894da45e
24/10/20 16:01:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/10/20 16:01:01 INFO SparkEnv: Registering OutputCommitCoordinator
24/10/20 16:01:01 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/10/20 16:01:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/10/20 16:01:01 INFO Executor: Starting executor ID driver on host localhost.localdomain
24/10/20 16:01:01 INFO Executor: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:01:01 INFO Executor: Java version 1.8.0_412
24/10/20 16:01:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/10/20 16:01:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@13f0a0b3 for default.
24/10/20 16:01:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36101.
24/10/20 16:01:01 INFO NettyBlockTransferService: Server created on localhost.localdomain:36101
24/10/20 16:01:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/10/20 16:01:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost.localdomain, 36101, None)
24/10/20 16:01:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost.localdomain:36101 with 366.3 MiB RAM, BlockManagerId(driver, localho
st.localdomain, 36101, None)
24/10/20 16:01:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost.localdomain, 36101, None)
24/10/20 16:01:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost.localdomain, 36101, None)
24/10/20 16:01:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 362.3 KiB, free 365.9 MiB)
24/10/20 16:01:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 365.9 MiB)
24/10/20 16:01:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost.localdomain:36101 (size: 33.0 KiB, free: 366.3 MiB)
24/10/20 16:01:02 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/10/20 16:01:02 INFO FileInputFormat: Total input files to process : 1
24/10/20 16:01:02 INFO SparkContext: Starting job: collectAsMap at /home/project2_rdd.py:43
24/10/20 16:01:02 INFO DAGScheduler: Registering RDD 4 (reduceByKey at /home/project2_rdd.py:43) as input to shuffle 0
24/10/20 16:01:02 INFO DAGScheduler: Got job 0 (collectAsMap at /home/project2_rdd.py:43) with 1 output partitions
24/10/20 16:01:02 INFO DAGScheduler: Final stage: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43)
24/10/20 16:01:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
24/10/20 16:01:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
24/10/20 16:01:02 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:01:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.9 MiB)
24/10/20 16:01:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.9 MiB)
24/10/20 16:01:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost.localdomain:36101 (size: 8.8 KiB, free: 366.3 MiB)
24/10/20 16:01:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:01:02 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/10/20 16:01:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:01:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/10/20 16:01:02 INFO HadoopRDD: Input split: file:/home/abcnews.txt:0+616
24/10/20 16:01:03 INFO PythonRunner: Times: total = 493, boot = 434, init = 59, finish = 0
24/10/20 16:01:03 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 603.0 B, free 365.9 MiB)
24/10/20 16:01:03 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost.localdomain:36101 (size: 603.0 B, free: 366.3 MiB)
24/10/20 16:01:03 INFO PythonRunner: Times: total = 49, boot = -111, init = 159, finish = 1
24/10/20 16:01:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1675 bytes result sent to driver
24/10/20 16:01:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 915 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:03 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 38655
24/10/20 16:01:03 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/project2_rdd.py:43) finished in 0.987 s
24/10/20 16:01:03 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:03 INFO DAGScheduler: running: Set()
24/10/20 16:01:03 INFO DAGScheduler: waiting: Set(ResultStage 1)
24/10/20 16:01:03 INFO DAGScheduler: failed: Set()
24/10/20 16:01:03 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:01:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 365.9 MiB)
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9 MiB)
24/10/20 16:01:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost.localdomain:36101 (size: 6.0 KiB, free: 366.3 MiB)
24/10/20 16:01:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43) (first 15 tas
ks are for partitions Vector(0))
24/10/20 16:01:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/10/20 16:01:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:01:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/10/20 16:01:03 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) p
ush-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/10/20 16:01:03 INFO PythonRunner: Times: total = 46, boot = -90, init = 136, finish = 0
24/10/20 16:01:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2111 bytes result sent to driver
24/10/20 16:01:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 87 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/10/20 16:01:03 INFO DAGScheduler: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43) finished in 0.100 s
24/10/20 16:01:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:01:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/10/20 16:01:03 INFO DAGScheduler: Job 0 finished: collectAsMap at /home/project2_rdd.py:43, took 1.154856 s
24/10/20 16:01:03 INFO SparkContext: Starting job: collect at /home/project2_rdd.py:49
24/10/20 16:01:03 INFO DAGScheduler: Registering RDD 9 (reduceByKey at /home/project2_rdd.py:48) as input to shuffle 1
24/10/20 16:01:03 INFO DAGScheduler: Got job 1 (collect at /home/project2_rdd.py:49) with 1 output partitions
24/10/20 16:01:03 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/project2_rdd.py:49)
24/10/20 16:01:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
24/10/20 16:01:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
24/10/20 16:01:03 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48), which has no missing parents
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.5 KiB, free 365.9 MiB)
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:01:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost.localdomain:36101 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:01:03 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:01:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/10/20 16:01:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:01:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/10/20 16:01:03 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:01:03 INFO PythonRunner: Times: total = 44, boot = -60, init = 104, finish = 0
24/10/20 16:01:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1589 bytes result sent to driver
24/10/20 16:01:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/10/20 16:01:03 INFO DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/project2_rdd.py:48) finished in 0.071 s
24/10/20 16:01:03 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:03 INFO DAGScheduler: running: Set()
24/10/20 16:01:03 INFO DAGScheduler: waiting: Set(ResultStage 3)
24/10/20 16:01:03 INFO DAGScheduler: failed: Set()
24/10/20 16:01:03 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49), which has no missing parents
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 365.8 MiB)
24/10/20 16:01:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.8 MiB)
24/10/20 16:01:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost.localdomain:36101 (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:01:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49) (first 15 tasks a
re for partitions Vector(0))
24/10/20 16:01:03 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/10/20 16:01:03 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:01:03 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/10/20 16:01:03 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:03 INFO PythonRunner: Times: total = 44, boot = -21, init = 65, finish = 0
24/10/20 16:01:03 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2973 bytes result sent to driver
24/10/20 16:01:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 57 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/10/20 16:01:03 INFO DAGScheduler: ResultStage 3 (collect at /home/project2_rdd.py:49) finished in 0.064 s
24/10/20 16:01:03 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:01:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/10/20 16:01:03 INFO DAGScheduler: Job 1 finished: collect at /home/project2_rdd.py:49, took 0.142784 s
24/10/20 16:01:04 INFO SparkContext: Starting job: takeOrdered at /home/project2_rdd.py:80
24/10/20 16:01:04 INFO DAGScheduler: Registering RDD 14 (reduceByKey at /home/project2_rdd.py:57) as input to shuffle 5
24/10/20 16:01:04 INFO DAGScheduler: Registering RDD 18 (reduceByKey at /home/project2_rdd.py:64) as input to shuffle 4
24/10/20 16:01:04 INFO DAGScheduler: Registering RDD 25 (join at /home/project2_rdd.py:70) as input to shuffle 3
24/10/20 16:01:04 INFO DAGScheduler: Registering RDD 29 (reduceByKey at /home/project2_rdd.py:75) as input to shuffle 2
24/10/20 16:01:04 INFO DAGScheduler: Got job 2 (takeOrdered at /home/project2_rdd.py:80) with 2 output partitions
24/10/20 16:01:04 INFO DAGScheduler: Final stage: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80)
24/10/20 16:01:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
24/10/20 16:01:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
24/10/20 16:01:04 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57), which has no missing parent
s
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost.localdomain:36101 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:01:04 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/10/20 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:01:04 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/10/20 16:01:04 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:01:04 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64), which has no missing parent
s
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost.localdomain:36101 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:01:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/10/20 16:01:04 INFO PythonRunner: Times: total = 45, boot = -69, init = 113, finish = 1
24/10/20 16:01:04 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1589 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:01:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 61 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:04 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/10/20 16:01:04 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/project2_rdd.py:57) finished in 0.068 s
24/10/20 16:01:04 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:04 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
24/10/20 16:01:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:01:04 INFO DAGScheduler: failed: Set()
24/10/20 16:01:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/10/20 16:01:04 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:01:04 INFO PythonRunner: Times: total = 49, boot = -10, init = 59, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1589 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 66 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:01:04 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/10/20 16:01:04 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at /home/project2_rdd.py:64) finished in 0.123 s
24/10/20 16:01:04 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:04 INFO DAGScheduler: running: Set()
24/10/20 16:01:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:01:04 INFO DAGScheduler: failed: Set()
24/10/20 16:01:04 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70), which has no missing parents
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.0 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.8 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost.localdomain:36101 (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70) (first 15 task
s are for partitions Vector(0, 1))
24/10/20 16:01:04 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
24/10/20 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:01:04 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:04 INFO PythonRunner: Times: total = 45, boot = -36, init = 81, finish = 0
24/10/20 16:01:04 INFO PythonRunner: Times: total = 110, boot = 11, init = 98, finish = 1
24/10/20 16:01:04 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2235 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:01:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 149 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:01:04 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:04 INFO PythonRunner: Times: total = 48, boot = -97, init = 145, finish = 0
24/10/20 16:01:04 INFO PythonRunner: Times: total = 96, boot = -14, init = 110, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 2278 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 163 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:01:04 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/10/20 16:01:04 INFO DAGScheduler: ShuffleMapStage 6 (join at /home/project2_rdd.py:70) finished in 0.317 s
24/10/20 16:01:04 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:04 INFO DAGScheduler: running: Set()
24/10/20 16:01:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/10/20 16:01:04 INFO DAGScheduler: failed: Set()
24/10/20 16:01:04 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75), which has no missing parent
s
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 365.7 MiB)
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 365.7 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost.localdomain:36101 (size: 9.6 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75) (first 
15 tasks are for partitions Vector(0, 1))
24/10/20 16:01:04 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
24/10/20 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:01:04 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 2 (980.0 B) non-empty blocks including 2 (980.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/10/20 16:01:04 INFO PythonRunner: Times: total = 58, boot = -107, init = 165, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:01:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 114 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:01:04 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 2 (1245.0 B) non-empty blocks including 2 (1245.0 B) local and 0 (0.0 B) host-local and 0 (0.0 
B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:04 INFO PythonRunner: Times: total = 90, boot = -160, init = 250, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 2235 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 119 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:01:04 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/10/20 16:01:04 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at /home/project2_rdd.py:75) finished in 0.244 s
24/10/20 16:01:04 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:01:04 INFO DAGScheduler: running: Set()
24/10/20 16:01:04 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/10/20 16:01:04 INFO DAGScheduler: failed: Set()
24/10/20 16:01:04 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80), which has no missing parents
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.2 KiB, free 365.7 MiB)
24/10/20 16:01:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.7 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost.localdomain:36101 (size: 7.4 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
24/10/20 16:01:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80) (first 15 tas
ks are for partitions Vector(0, 1))
24/10/20 16:01:04 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/10/20 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:01:04 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost.localdomain:36101 in memory (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 2 (532.0 B) non-empty blocks including 2 (532.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost.localdomain:36101 in memory (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost.localdomain:36101 in memory (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost.localdomain:36101 in memory (size: 8.8 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost.localdomain:36101 in memory (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost.localdomain:36101 in memory (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:01:04 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost.localdomain:36101 in memory (size: 9.1 KiB, free: 366.3 MiB)
24/10/20 16:01:04 INFO PythonRunner: Times: total = 71, boot = -192, init = 263, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2168 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:01:04 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 90 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:01:04 INFO Executor: Running task 1.0 in stage 8.0 (TID 11)
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Getting 2 (490.0 B) non-empty blocks including 2 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:01:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:01:04 INFO PythonRunner: Times: total = 49, boot = -128, init = 177, finish = 0
24/10/20 16:01:04 INFO Executor: Finished task 1.0 in stage 8.0 (TID 11). 2154 bytes result sent to driver
24/10/20 16:01:04 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 67 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:01:04 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/10/20 16:01:04 INFO DAGScheduler: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80) finished in 0.201 s
24/10/20 16:01:04 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:01:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/10/20 16:01:04 INFO DAGScheduler: Job 2 finished: takeOrdered at /home/project2_rdd.py:80, took 0.909800 s
Traceback (most recent call last):
  File "/home/project2_rdd.py", line 95, in <module>
    Project2().run(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
  File "/home/project2_rdd.py", line 86, in run
    .coalesce(1).saveAsTextFile(output_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apache-spark/python/lib/pyspark.zip/pyspark/rdd.py", line 3425, in saveAsTextFile
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o187.saveAsTextFile.
: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/output already exists
at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)
at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)
at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
at java.lang.Thread.run(Thread.java:750)

24/10/20 16:01:05 INFO SparkContext: Invoking stop() from shutdown hook
24/10/20 16:01:05 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/10/20 16:01:05 INFO SparkUI: Stopped Spark web UI at http://localhost.localdomain:4040
24/10/20 16:01:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/10/20 16:01:05 INFO MemoryStore: MemoryStore cleared
24/10/20 16:01:05 INFO BlockManager: BlockManager stopped
24/10/20 16:01:05 INFO BlockManagerMaster: BlockManagerMaster stopped
24/10/20 16:01:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/10/20 16:01:05 INFO SparkContext: Successfully stopped SparkContext
24/10/20 16:01:05 INFO ShutdownHookManager: Shutdown hook called
24/10/20 16:01:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-5a98fa73-96c1-43c9-9056-07937f9e884a
24/10/20 16:01:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-3e23d36f-bd36-423c-a860-61d89a9037cf
24/10/20 16:01:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-3e23d36f-bd36-423c-a860-61d89a9037cf/pyspark-4417ec62-9274-4e53-8bc8-b86e4ab1d885
[user@sahara ~]$ cat home/output/part-*
cat: 'home/output/part-*': No such file or directory
Initialising Hadoop ...
Starting HDFS and YARN ...
Starting namenodes on [sahara]
Starting datanodes
Starting secondary namenodes [sahara]
Starting resourcemanager
Starting nodemanagers
[user@sahara ~]$ $ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
bash: $: command not found
[user@sahara ~]$ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
24/10/20 16:01:58 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!
24/10/20 16:01:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/10/20 16:01:59 INFO SparkContext: Running Spark version 3.5.0
24/10/20 16:01:59 INFO SparkContext: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:01:59 INFO SparkContext: Java version 1.8.0_412
24/10/20 16:01:59 INFO ResourceUtils: ==============================================================
24/10/20 16:01:59 INFO ResourceUtils: No custom resources configured for spark.driver.
24/10/20 16:01:59 INFO ResourceUtils: ==============================================================
24/10/20 16:01:59 INFO SparkContext: Submitted application: project2_rdd
24/10/20 16:01:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memor
y -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amou
nt: 1.0)
24/10/20 16:01:59 INFO ResourceProfile: Limiting resource is cpu
24/10/20 16:01:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/10/20 16:01:59 INFO SecurityManager: Changing view acls to: user
24/10/20 16:01:59 INFO SecurityManager: Changing modify acls to: user
24/10/20 16:01:59 INFO SecurityManager: Changing view acls groups to: 
24/10/20 16:01:59 INFO SecurityManager: Changing modify acls groups to: 
24/10/20 16:01:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user; groups with view per
missions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY
24/10/20 16:01:59 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: 04:1e:63:39:dd:e2:a8:f9
24/10/20 16:01:59 INFO Utils: Successfully started service 'sparkDriver' on port 42599.
24/10/20 16:01:59 INFO SparkEnv: Registering MapOutputTracker
24/10/20 16:01:59 INFO SparkEnv: Registering BlockManagerMaster
24/10/20 16:01:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/10/20 16:01:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/10/20 16:01:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/10/20 16:01:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-743075bb-e827-403a-9979-bc48156781f2
24/10/20 16:01:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/10/20 16:01:59 INFO SparkEnv: Registering OutputCommitCoordinator
24/10/20 16:01:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/10/20 16:01:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/10/20 16:01:59 INFO Executor: Starting executor ID driver on host localhost.localdomain
24/10/20 16:01:59 INFO Executor: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:01:59 INFO Executor: Java version 1.8.0_412
24/10/20 16:01:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/10/20 16:01:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@116348c9 for default.
24/10/20 16:01:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39771.
24/10/20 16:01:59 INFO NettyBlockTransferService: Server created on localhost.localdomain:39771
24/10/20 16:01:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/10/20 16:01:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost.localdomain, 39771, None)
24/10/20 16:01:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost.localdomain:39771 with 366.3 MiB RAM, BlockManagerId(driver, localho
st.localdomain, 39771, None)
24/10/20 16:01:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost.localdomain, 39771, None)
24/10/20 16:01:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost.localdomain, 39771, None)
24/10/20 16:02:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 362.3 KiB, free 365.9 MiB)
24/10/20 16:02:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 365.9 MiB)
24/10/20 16:02:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost.localdomain:39771 (size: 33.0 KiB, free: 366.3 MiB)
24/10/20 16:02:00 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/10/20 16:02:00 INFO FileInputFormat: Total input files to process : 1
24/10/20 16:02:00 INFO SparkContext: Starting job: collectAsMap at /home/project2_rdd.py:43
24/10/20 16:02:00 INFO DAGScheduler: Registering RDD 4 (reduceByKey at /home/project2_rdd.py:43) as input to shuffle 0
24/10/20 16:02:00 INFO DAGScheduler: Got job 0 (collectAsMap at /home/project2_rdd.py:43) with 1 output partitions
24/10/20 16:02:00 INFO DAGScheduler: Final stage: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43)
24/10/20 16:02:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
24/10/20 16:02:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
24/10/20 16:02:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:02:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.9 MiB)
24/10/20 16:02:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.9 MiB)
24/10/20 16:02:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost.localdomain:39771 (size: 8.8 KiB, free: 366.3 MiB)
24/10/20 16:02:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:02:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/10/20 16:02:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:02:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/10/20 16:02:01 INFO HadoopRDD: Input split: file:/home/abcnews.txt:0+616
24/10/20 16:02:01 INFO PythonRunner: Times: total = 522, boot = 451, init = 71, finish = 0
24/10/20 16:02:01 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 603.0 B, free 365.9 MiB)
24/10/20 16:02:01 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost.localdomain:39771 (size: 603.0 B, free: 366.3 MiB)
24/10/20 16:02:01 INFO PythonRunner: Times: total = 50, boot = -53, init = 103, finish = 0
24/10/20 16:02:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1675 bytes result sent to driver
24/10/20 16:02:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 936 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/10/20 16:02:01 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 52085
24/10/20 16:02:01 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/project2_rdd.py:43) finished in 1.029 s
24/10/20 16:02:01 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:01 INFO DAGScheduler: running: Set()
24/10/20 16:02:01 INFO DAGScheduler: waiting: Set(ResultStage 1)
24/10/20 16:02:01 INFO DAGScheduler: failed: Set()
24/10/20 16:02:01 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:02:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 365.9 MiB)
24/10/20 16:02:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9 MiB)
24/10/20 16:02:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost.localdomain:39771 (size: 6.0 KiB, free: 366.3 MiB)
24/10/20 16:02:01 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43) (first 15 tas
ks are for partitions Vector(0))
24/10/20 16:02:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/10/20 16:02:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:02:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/10/20 16:02:01 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) p
ush-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/10/20 16:02:01 INFO PythonRunner: Times: total = 49, boot = -99, init = 148, finish = 0
24/10/20 16:02:01 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2111 bytes result sent to driver
24/10/20 16:02:01 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 92 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:01 INFO DAGScheduler: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43) finished in 0.101 s
24/10/20 16:02:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/10/20 16:02:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:02:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/10/20 16:02:01 INFO DAGScheduler: Job 0 finished: collectAsMap at /home/project2_rdd.py:43, took 1.209100 s
24/10/20 16:02:01 INFO SparkContext: Starting job: collect at /home/project2_rdd.py:49
24/10/20 16:02:01 INFO DAGScheduler: Registering RDD 9 (reduceByKey at /home/project2_rdd.py:48) as input to shuffle 1
24/10/20 16:02:01 INFO DAGScheduler: Got job 1 (collect at /home/project2_rdd.py:49) with 1 output partitions
24/10/20 16:02:01 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/project2_rdd.py:49)
24/10/20 16:02:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
24/10/20 16:02:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
24/10/20 16:02:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48), which has no missing parents
24/10/20 16:02:01 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.5 KiB, free 365.9 MiB)
24/10/20 16:02:01 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost.localdomain:39771 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/10/20 16:02:02 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:02:02 INFO PythonRunner: Times: total = 44, boot = -55, init = 99, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1589 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 65 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/project2_rdd.py:48) finished in 0.074 s
24/10/20 16:02:02 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:02 INFO DAGScheduler: running: Set()
24/10/20 16:02:02 INFO DAGScheduler: waiting: Set(ResultStage 3)
24/10/20 16:02:02 INFO DAGScheduler: failed: Set()
24/10/20 16:02:02 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49), which has no missing parents
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost.localdomain:39771 (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49) (first 15 tasks a
re for partitions Vector(0))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 43, boot = -16, init = 59, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2973 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 58 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ResultStage 3 (collect at /home/project2_rdd.py:49) finished in 0.064 s
24/10/20 16:02:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:02:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/10/20 16:02:02 INFO DAGScheduler: Job 1 finished: collect at /home/project2_rdd.py:49, took 0.145231 s
24/10/20 16:02:02 INFO SparkContext: Starting job: takeOrdered at /home/project2_rdd.py:80
24/10/20 16:02:02 INFO DAGScheduler: Registering RDD 18 (reduceByKey at /home/project2_rdd.py:64) as input to shuffle 4
24/10/20 16:02:02 INFO DAGScheduler: Registering RDD 14 (reduceByKey at /home/project2_rdd.py:57) as input to shuffle 5
24/10/20 16:02:02 INFO DAGScheduler: Registering RDD 25 (join at /home/project2_rdd.py:70) as input to shuffle 3
24/10/20 16:02:02 INFO DAGScheduler: Registering RDD 29 (reduceByKey at /home/project2_rdd.py:75) as input to shuffle 2
24/10/20 16:02:02 INFO DAGScheduler: Got job 2 (takeOrdered at /home/project2_rdd.py:80) with 2 output partitions
24/10/20 16:02:02 INFO DAGScheduler: Final stage: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80)
24/10/20 16:02:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
24/10/20 16:02:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
24/10/20 16:02:02 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64), which has no missing parent
s
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost.localdomain:39771 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/10/20 16:02:02 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57), which has no missing parent
s
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/10/20 16:02:02 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost.localdomain:39771 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/10/20 16:02:02 INFO PythonRunner: Times: total = 48, boot = -81, init = 129, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1589 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 60 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/project2_rdd.py:64) finished in 0.069 s
24/10/20 16:02:02 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:02 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
24/10/20 16:02:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:02:02 INFO DAGScheduler: failed: Set()
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/10/20 16:02:02 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:02:02 INFO PythonRunner: Times: total = 41, boot = 3, init = 38, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1589 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 61 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at /home/project2_rdd.py:57) finished in 0.118 s
24/10/20 16:02:02 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:02 INFO DAGScheduler: running: Set()
24/10/20 16:02:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:02:02 INFO DAGScheduler: failed: Set()
24/10/20 16:02:02 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70), which has no missing parents
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.0 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.8 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost.localdomain:39771 (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70) (first 15 task
s are for partitions Vector(0, 1))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 41, boot = -29, init = 70, finish = 0
24/10/20 16:02:02 INFO PythonRunner: Times: total = 67, boot = 3, init = 63, finish = 1
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2235 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:02:02 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 109 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 49, boot = -57, init = 106, finish = 0
24/10/20 16:02:02 INFO PythonRunner: Times: total = 45, boot = -24, init = 68, finish = 1
24/10/20 16:02:02 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 2235 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 79 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ShuffleMapStage 6 (join at /home/project2_rdd.py:70) finished in 0.196 s
24/10/20 16:02:02 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:02 INFO DAGScheduler: running: Set()
24/10/20 16:02:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/10/20 16:02:02 INFO DAGScheduler: failed: Set()
24/10/20 16:02:02 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75), which has no missing parent
s
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 365.7 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 365.7 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost.localdomain:39771 (size: 9.6 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75) (first 
15 tasks are for partitions Vector(0, 1))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 2 (980.0 B) non-empty blocks including 2 (980.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 42, boot = -19, init = 60, finish = 1
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 63 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:02:02 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 2 (1245.0 B) non-empty blocks including 2 (1245.0 B) local and 0 (0.0 B) host-local and 0 (0.0 
B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 44, boot = -85, init = 128, finish = 1
24/10/20 16:02:02 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 2235 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 67 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at /home/project2_rdd.py:75) finished in 0.136 s
24/10/20 16:02:02 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:02 INFO DAGScheduler: running: Set()
24/10/20 16:02:02 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/10/20 16:02:02 INFO DAGScheduler: failed: Set()
24/10/20 16:02:02 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80), which has no missing parents
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.2 KiB, free 365.7 MiB)
24/10/20 16:02:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.7 MiB)
24/10/20 16:02:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost.localdomain:39771 (size: 7.4 KiB, free: 366.2 MiB)
24/10/20 16:02:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:02 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80) (first 15 tas
ks are for partitions Vector(0, 1))
24/10/20 16:02:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/10/20 16:02:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:02:02 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 2 (532.0 B) non-empty blocks including 2 (532.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 46, boot = -85, init = 131, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2168 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:02:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 59 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:02:02 INFO Executor: Running task 1.0 in stage 8.0 (TID 11)
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Getting 2 (490.0 B) non-empty blocks including 2 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:02:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/10/20 16:02:02 INFO PythonRunner: Times: total = 43, boot = -87, init = 130, finish = 0
24/10/20 16:02:02 INFO Executor: Finished task 1.0 in stage 8.0 (TID 11). 2154 bytes result sent to driver
24/10/20 16:02:02 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 63 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:02:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/10/20 16:02:02 INFO DAGScheduler: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80) finished in 0.126 s
24/10/20 16:02:02 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:02:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/10/20 16:02:02 INFO DAGScheduler: Job 2 finished: takeOrdered at /home/project2_rdd.py:80, took 0.604679 s
Traceback (most recent call last):
  File "/home/project2_rdd.py", line 95, in <module>
    Project2().run(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
  File "/home/project2_rdd.py", line 86, in run
    .coalesce(1).saveAsTextFile(output_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apache-spark/python/lib/pyspark.zip/pyspark/rdd.py", line 3425, in saveAsTextFile
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o187.saveAsTextFile.
: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/output already exists
at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)
at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)
at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
at java.lang.Thread.run(Thread.java:750)

24/10/20 16:02:02 INFO SparkContext: Invoking stop() from shutdown hook
24/10/20 16:02:02 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/10/20 16:02:02 INFO SparkUI: Stopped Spark web UI at http://localhost.localdomain:4040
24/10/20 16:02:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/10/20 16:02:02 INFO MemoryStore: MemoryStore cleared
24/10/20 16:02:02 INFO BlockManager: BlockManager stopped
24/10/20 16:02:02 INFO BlockManagerMaster: BlockManagerMaster stopped
24/10/20 16:02:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/10/20 16:02:02 INFO SparkContext: Successfully stopped SparkContext
24/10/20 16:02:02 INFO ShutdownHookManager: Shutdown hook called
24/10/20 16:02:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e3baaa9-761c-4fb7-89c8-81360f4fb108
24/10/20 16:02:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc243813-d2e0-4a33-82f7-ef67fb7b752d
24/10/20 16:02:02 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc243813-d2e0-4a33-82f7-ef67fb7b752d/pyspark-75b1bf13-e7b8-4c34-a767-95ea4c162186
[user@sahara ~]$ cat/home/output/part-*
bash: cat/home/output/part-*: No such file or directory
[user@sahara ~]$ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
24/10/20 16:02:56 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!
24/10/20 16:02:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/10/20 16:02:57 INFO SparkContext: Running Spark version 3.5.0
24/10/20 16:02:57 INFO SparkContext: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:02:57 INFO SparkContext: Java version 1.8.0_412
24/10/20 16:02:57 INFO ResourceUtils: ==============================================================
24/10/20 16:02:57 INFO ResourceUtils: No custom resources configured for spark.driver.
24/10/20 16:02:57 INFO ResourceUtils: ==============================================================
24/10/20 16:02:57 INFO SparkContext: Submitted application: project2_rdd
24/10/20 16:02:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memor
y -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amou
nt: 1.0)
24/10/20 16:02:57 INFO ResourceProfile: Limiting resource is cpu
24/10/20 16:02:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/10/20 16:02:57 INFO SecurityManager: Changing view acls to: user
24/10/20 16:02:57 INFO SecurityManager: Changing modify acls to: user
24/10/20 16:02:57 INFO SecurityManager: Changing view acls groups to: 
24/10/20 16:02:57 INFO SecurityManager: Changing modify acls groups to: 
24/10/20 16:02:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user; groups with view per
missions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY
24/10/20 16:02:57 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: 0d:ad:b8:97:43:ba:2f:c9
24/10/20 16:02:57 INFO Utils: Successfully started service 'sparkDriver' on port 33717.
24/10/20 16:02:57 INFO SparkEnv: Registering MapOutputTracker
24/10/20 16:02:57 INFO SparkEnv: Registering BlockManagerMaster
24/10/20 16:02:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/10/20 16:02:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/10/20 16:02:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/10/20 16:02:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3760c259-bcc1-4d78-bb6f-bf6cf6428950
24/10/20 16:02:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/10/20 16:02:57 INFO SparkEnv: Registering OutputCommitCoordinator
24/10/20 16:02:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/10/20 16:02:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/10/20 16:02:58 INFO Executor: Starting executor ID driver on host localhost.localdomain
24/10/20 16:02:58 INFO Executor: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:02:58 INFO Executor: Java version 1.8.0_412
24/10/20 16:02:58 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/10/20 16:02:58 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@61c9a4f for default.
24/10/20 16:02:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38341.
24/10/20 16:02:58 INFO NettyBlockTransferService: Server created on localhost.localdomain:38341
24/10/20 16:02:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/10/20 16:02:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost.localdomain, 38341, None)
24/10/20 16:02:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost.localdomain:38341 with 366.3 MiB RAM, BlockManagerId(driver, localho
st.localdomain, 38341, None)
24/10/20 16:02:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost.localdomain, 38341, None)
24/10/20 16:02:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost.localdomain, 38341, None)
24/10/20 16:02:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 362.3 KiB, free 365.9 MiB)
24/10/20 16:02:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 365.9 MiB)
24/10/20 16:02:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost.localdomain:38341 (size: 33.0 KiB, free: 366.3 MiB)
24/10/20 16:02:58 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/10/20 16:02:58 INFO FileInputFormat: Total input files to process : 1
24/10/20 16:02:58 INFO SparkContext: Starting job: collectAsMap at /home/project2_rdd.py:43
24/10/20 16:02:58 INFO DAGScheduler: Registering RDD 4 (reduceByKey at /home/project2_rdd.py:43) as input to shuffle 0
24/10/20 16:02:58 INFO DAGScheduler: Got job 0 (collectAsMap at /home/project2_rdd.py:43) with 1 output partitions
24/10/20 16:02:58 INFO DAGScheduler: Final stage: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43)
24/10/20 16:02:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
24/10/20 16:02:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
24/10/20 16:02:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:02:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.9 MiB)
24/10/20 16:02:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.9 MiB)
24/10/20 16:02:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost.localdomain:38341 (size: 8.8 KiB, free: 366.3 MiB)
24/10/20 16:02:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:02:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/10/20 16:02:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:02:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/10/20 16:02:59 INFO HadoopRDD: Input split: file:/home/abcnews.txt:0+616
24/10/20 16:02:59 INFO PythonRunner: Times: total = 568, boot = 461, init = 107, finish = 0
24/10/20 16:02:59 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 603.0 B, free 365.9 MiB)
24/10/20 16:02:59 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost.localdomain:38341 (size: 603.0 B, free: 366.3 MiB)
24/10/20 16:02:59 INFO PythonRunner: Times: total = 41, boot = -38, init = 78, finish = 1
24/10/20 16:02:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1675 bytes result sent to driver
24/10/20 16:02:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 905 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:02:59 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 39915
24/10/20 16:02:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/10/20 16:02:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/project2_rdd.py:43) finished in 0.970 s
24/10/20 16:02:59 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:02:59 INFO DAGScheduler: running: Set()
24/10/20 16:02:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
24/10/20 16:02:59 INFO DAGScheduler: failed: Set()
24/10/20 16:02:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:02:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 365.9 MiB)
24/10/20 16:02:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9 MiB)
24/10/20 16:02:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost.localdomain:38341 (size: 6.0 KiB, free: 366.3 MiB)
24/10/20 16:02:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
24/10/20 16:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43) (first 15 tas
ks are for partitions Vector(0))
24/10/20 16:02:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/10/20 16:02:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:02:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) p
ush-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 44, boot = -115, init = 159, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2111 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 104 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43) finished in 0.121 s
24/10/20 16:03:00 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/10/20 16:03:00 INFO DAGScheduler: Job 0 finished: collectAsMap at /home/project2_rdd.py:43, took 1.146627 s
24/10/20 16:03:00 INFO SparkContext: Starting job: collect at /home/project2_rdd.py:49
24/10/20 16:03:00 INFO DAGScheduler: Registering RDD 9 (reduceByKey at /home/project2_rdd.py:48) as input to shuffle 1
24/10/20 16:03:00 INFO DAGScheduler: Got job 1 (collect at /home/project2_rdd.py:49) with 1 output partitions
24/10/20 16:03:00 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/project2_rdd.py:49)
24/10/20 16:03:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
24/10/20 16:03:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
24/10/20 16:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48), which has no missing parents
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.5 KiB, free 365.9 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost.localdomain:38341 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/10/20 16:03:00 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:00 INFO PythonRunner: Times: total = 53, boot = -55, init = 108, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1589 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 73 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/project2_rdd.py:48) finished in 0.085 s
24/10/20 16:03:00 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:00 INFO DAGScheduler: running: Set()
24/10/20 16:03:00 INFO DAGScheduler: waiting: Set(ResultStage 3)
24/10/20 16:03:00 INFO DAGScheduler: failed: Set()
24/10/20 16:03:00 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49), which has no missing parents
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost.localdomain:38341 (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49) (first 15 tasks a
re for partitions Vector(0))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 44, boot = -21, init = 65, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2973 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 59 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ResultStage 3 (collect at /home/project2_rdd.py:49) finished in 0.064 s
24/10/20 16:03:00 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/10/20 16:03:00 INFO DAGScheduler: Job 1 finished: collect at /home/project2_rdd.py:49, took 0.156209 s
24/10/20 16:03:00 INFO SparkContext: Starting job: takeOrdered at /home/project2_rdd.py:80
24/10/20 16:03:00 INFO DAGScheduler: Registering RDD 14 (reduceByKey at /home/project2_rdd.py:57) as input to shuffle 5
24/10/20 16:03:00 INFO DAGScheduler: Registering RDD 18 (reduceByKey at /home/project2_rdd.py:64) as input to shuffle 4
24/10/20 16:03:00 INFO DAGScheduler: Registering RDD 25 (join at /home/project2_rdd.py:70) as input to shuffle 3
24/10/20 16:03:00 INFO DAGScheduler: Registering RDD 29 (reduceByKey at /home/project2_rdd.py:75) as input to shuffle 2
24/10/20 16:03:00 INFO DAGScheduler: Got job 2 (takeOrdered at /home/project2_rdd.py:80) with 2 output partitions
24/10/20 16:03:00 INFO DAGScheduler: Final stage: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80)
24/10/20 16:03:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
24/10/20 16:03:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
24/10/20 16:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57), which has no missing parent
s
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost.localdomain:38341 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/10/20 16:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64), which has no missing parent
s
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/10/20 16:03:00 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost.localdomain:38341 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/10/20 16:03:00 INFO PythonRunner: Times: total = 46, boot = -75, init = 121, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1589 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 65 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/project2_rdd.py:57) finished in 0.072 s
24/10/20 16:03:00 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:00 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
24/10/20 16:03:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:00 INFO DAGScheduler: failed: Set()
24/10/20 16:03:00 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:00 INFO PythonRunner: Times: total = 47, boot = -21, init = 68, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1589 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 75 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at /home/project2_rdd.py:64) finished in 0.139 s
24/10/20 16:03:00 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:00 INFO DAGScheduler: running: Set()
24/10/20 16:03:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:00 INFO DAGScheduler: failed: Set()
24/10/20 16:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70), which has no missing parents
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.0 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.8 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost.localdomain:38341 (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70) (first 15 task
s are for partitions Vector(0, 1))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 51, boot = -26, init = 77, finish = 0
24/10/20 16:03:00 INFO PythonRunner: Times: total = 76, boot = 11, init = 64, finish = 1
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2235 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 97 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:00 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 45, boot = -36, init = 81, finish = 0
24/10/20 16:03:00 INFO PythonRunner: Times: total = 51, boot = -10, init = 60, finish = 1
24/10/20 16:03:00 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 2235 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 70 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ShuffleMapStage 6 (join at /home/project2_rdd.py:70) finished in 0.176 s
24/10/20 16:03:00 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:00 INFO DAGScheduler: running: Set()
24/10/20 16:03:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:00 INFO DAGScheduler: failed: Set()
24/10/20 16:03:00 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75), which has no missing parent
s
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 365.7 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 365.7 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost.localdomain:38341 (size: 9.6 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75) (first 
15 tasks are for partitions Vector(0, 1))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 2 (980.0 B) non-empty blocks including 2 (980.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 42, boot = -25, init = 66, finish = 1
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 2192 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 70 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:00 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 2 (1245.0 B) non-empty blocks including 2 (1245.0 B) local and 0 (0.0 B) host-local and 0 (0.0 
B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 45, boot = -69, init = 113, finish = 1
24/10/20 16:03:00 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 2235 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 69 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at /home/project2_rdd.py:75) finished in 0.145 s
24/10/20 16:03:00 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:00 INFO DAGScheduler: running: Set()
24/10/20 16:03:00 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/10/20 16:03:00 INFO DAGScheduler: failed: Set()
24/10/20 16:03:00 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80), which has no missing parents
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.2 KiB, free 365.7 MiB)
24/10/20 16:03:00 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.7 MiB)
24/10/20 16:03:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost.localdomain:38341 (size: 7.4 KiB, free: 366.2 MiB)
24/10/20 16:03:00 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80) (first 15 tas
ks are for partitions Vector(0, 1))
24/10/20 16:03:00 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/10/20 16:03:00 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:03:00 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 2 (532.0 B) non-empty blocks including 2 (532.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 42, boot = -93, init = 135, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2168 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:03:00 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 50 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:00 INFO Executor: Running task 1.0 in stage 8.0 (TID 11)
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Getting 2 (490.0 B) non-empty blocks including 2 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:00 INFO PythonRunner: Times: total = 41, boot = -75, init = 116, finish = 0
24/10/20 16:03:00 INFO Executor: Finished task 1.0 in stage 8.0 (TID 11). 2154 bytes result sent to driver
24/10/20 16:03:00 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 54 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:00 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/10/20 16:03:00 INFO DAGScheduler: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80) finished in 0.107 s
24/10/20 16:03:00 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/10/20 16:03:00 INFO DAGScheduler: Job 2 finished: takeOrdered at /home/project2_rdd.py:80, took 0.587844 s
Traceback (most recent call last):
  File "/home/project2_rdd.py", line 95, in <module>
    Project2().run(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
  File "/home/project2_rdd.py", line 86, in run
    .coalesce(1).saveAsTextFile(output_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apache-spark/python/lib/pyspark.zip/pyspark/rdd.py", line 3425, in saveAsTextFile
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o187.saveAsTextFile.
: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/output already exists
at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)
at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)
at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
at java.lang.Thread.run(Thread.java:750)

[user@sahara ~]$ spark-submit project2_rdd.py "file:///home/abcnews.txt" "file:///home/output" 1 5
24/10/20 16:03:44 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!
24/10/20 16:03:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/10/20 16:03:45 INFO SparkContext: Running Spark version 3.5.0
24/10/20 16:03:45 INFO SparkContext: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:03:45 INFO SparkContext: Java version 1.8.0_412
24/10/20 16:03:45 INFO ResourceUtils: ==============================================================
24/10/20 16:03:45 INFO ResourceUtils: No custom resources configured for spark.driver.
24/10/20 16:03:45 INFO ResourceUtils: ==============================================================
24/10/20 16:03:45 INFO SparkContext: Submitted application: project2_rdd
24/10/20 16:03:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memor
y -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amou
nt: 1.0)
24/10/20 16:03:45 INFO ResourceProfile: Limiting resource is cpu
24/10/20 16:03:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/10/20 16:03:45 INFO SecurityManager: Changing view acls to: user
24/10/20 16:03:45 INFO SecurityManager: Changing modify acls to: user
24/10/20 16:03:45 INFO SecurityManager: Changing view acls groups to: 
24/10/20 16:03:45 INFO SecurityManager: Changing modify acls groups to: 
24/10/20 16:03:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user; groups with view per
missions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY
24/10/20 16:03:45 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: 6b:ec:2f:58:be:4b:88:f0
24/10/20 16:03:45 INFO Utils: Successfully started service 'sparkDriver' on port 36267.
24/10/20 16:03:45 INFO SparkEnv: Registering MapOutputTracker
24/10/20 16:03:45 INFO SparkEnv: Registering BlockManagerMaster
24/10/20 16:03:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/10/20 16:03:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/10/20 16:03:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/10/20 16:03:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b1aa2d2f-3f28-4533-b3b1-9cbfaac74ddd
24/10/20 16:03:46 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/10/20 16:03:46 INFO SparkEnv: Registering OutputCommitCoordinator
24/10/20 16:03:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/10/20 16:03:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/10/20 16:03:46 INFO Executor: Starting executor ID driver on host localhost.localdomain
24/10/20 16:03:46 INFO Executor: OS info Linux, 5.15.0-113-generic, amd64
24/10/20 16:03:46 INFO Executor: Java version 1.8.0_412
24/10/20 16:03:46 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/10/20 16:03:46 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@27d888f5 for default.
24/10/20 16:03:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40059.
24/10/20 16:03:46 INFO NettyBlockTransferService: Server created on localhost.localdomain:40059
24/10/20 16:03:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/10/20 16:03:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost.localdomain, 40059, None)
24/10/20 16:03:46 INFO BlockManagerMasterEndpoint: Registering block manager localhost.localdomain:40059 with 366.3 MiB RAM, BlockManagerId(driver, localho
st.localdomain, 40059, None)
24/10/20 16:03:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost.localdomain, 40059, None)
24/10/20 16:03:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost.localdomain, 40059, None)
24/10/20 16:03:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 362.3 KiB, free 365.9 MiB)
24/10/20 16:03:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 365.9 MiB)
24/10/20 16:03:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost.localdomain:40059 (size: 33.0 KiB, free: 366.3 MiB)
24/10/20 16:03:46 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/10/20 16:03:47 INFO FileInputFormat: Total input files to process : 1
24/10/20 16:03:47 INFO SparkContext: Starting job: collectAsMap at /home/project2_rdd.py:43
24/10/20 16:03:47 INFO DAGScheduler: Registering RDD 4 (reduceByKey at /home/project2_rdd.py:43) as input to shuffle 0
24/10/20 16:03:47 INFO DAGScheduler: Got job 0 (collectAsMap at /home/project2_rdd.py:43) with 1 output partitions
24/10/20 16:03:47 INFO DAGScheduler: Final stage: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43)
24/10/20 16:03:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
24/10/20 16:03:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
24/10/20 16:03:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:03:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.9 MiB)
24/10/20 16:03:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.9 MiB)
24/10/20 16:03:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost.localdomain:40059 (size: 8.8 KiB, free: 366.3 MiB)
24/10/20 16:03:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[4] at reduceByKey at /home/project2_rdd.py:43) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:03:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/10/20 16:03:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/10/20 16:03:47 INFO HadoopRDD: Input split: file:/home/abcnews.txt:0+616
24/10/20 16:03:48 INFO PythonRunner: Times: total = 615, boot = 485, init = 130, finish = 0
24/10/20 16:03:48 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 603.0 B, free 365.9 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost.localdomain:40059 (size: 603.0 B, free: 366.3 MiB)
24/10/20 16:03:48 INFO PythonRunner: Times: total = 63, boot = -30, init = 92, finish = 1
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1675 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1031 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 33121
24/10/20 16:03:48 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/project2_rdd.py:43) finished in 1.109 s
24/10/20 16:03:48 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:48 INFO DAGScheduler: running: Set()
24/10/20 16:03:48 INFO DAGScheduler: waiting: Set(ResultStage 1)
24/10/20 16:03:48 INFO DAGScheduler: failed: Set()
24/10/20 16:03:48 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43), which has no missing parents
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.0 KiB, free 365.9 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.9 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost.localdomain:40059 (size: 6.0 KiB, free: 366.3 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at collectAsMap at /home/project2_rdd.py:43) (first 15 tas
ks are for partitions Vector(0))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) p
ush-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
24/10/20 16:03:48 INFO PythonRunner: Times: total = 51, boot = -126, init = 176, finish = 1
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2111 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 116 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO DAGScheduler: ResultStage 1 (collectAsMap at /home/project2_rdd.py:43) finished in 0.131 s
24/10/20 16:03:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/10/20 16:03:48 INFO DAGScheduler: Job 0 finished: collectAsMap at /home/project2_rdd.py:43, took 1.314253 s
24/10/20 16:03:48 INFO SparkContext: Starting job: collect at /home/project2_rdd.py:49
24/10/20 16:03:48 INFO DAGScheduler: Registering RDD 9 (reduceByKey at /home/project2_rdd.py:48) as input to shuffle 1
24/10/20 16:03:48 INFO DAGScheduler: Got job 1 (collect at /home/project2_rdd.py:49) with 1 output partitions
24/10/20 16:03:48 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /home/project2_rdd.py:49)
24/10/20 16:03:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
24/10/20 16:03:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
24/10/20 16:03:48 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48), which has no missing parents
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.5 KiB, free 365.9 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost.localdomain:40059 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (PairwiseRDD[9] at reduceByKey at /home/project2_rdd.py:48) (first 1
5 tasks are for partitions Vector(0))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/10/20 16:03:48 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:48 INFO PythonRunner: Times: total = 55, boot = -65, init = 120, finish = 0
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1589 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 73 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO DAGScheduler: ShuffleMapStage 2 (reduceByKey at /home/project2_rdd.py:48) finished in 0.080 s
24/10/20 16:03:48 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:48 INFO DAGScheduler: running: Set()
24/10/20 16:03:48 INFO DAGScheduler: waiting: Set(ResultStage 3)
24/10/20 16:03:48 INFO DAGScheduler: failed: Set()
24/10/20 16:03:48 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49), which has no missing parents
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost.localdomain:40059 (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[12] at collect at /home/project2_rdd.py:49) (first 15 tasks a
re for partitions Vector(0))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes)
 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:48 INFO PythonRunner: Times: total = 43, boot = -17, init = 60, finish = 0
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2973 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 59 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO DAGScheduler: ResultStage 3 (collect at /home/project2_rdd.py:49) finished in 0.064 s
24/10/20 16:03:48 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/10/20 16:03:48 INFO DAGScheduler: Job 1 finished: collect at /home/project2_rdd.py:49, took 0.152115 s
24/10/20 16:03:48 INFO SparkContext: Starting job: takeOrdered at /home/project2_rdd.py:80
24/10/20 16:03:48 INFO DAGScheduler: Registering RDD 14 (reduceByKey at /home/project2_rdd.py:57) as input to shuffle 5
24/10/20 16:03:48 INFO DAGScheduler: Registering RDD 18 (reduceByKey at /home/project2_rdd.py:64) as input to shuffle 4
24/10/20 16:03:48 INFO DAGScheduler: Registering RDD 25 (join at /home/project2_rdd.py:70) as input to shuffle 3
24/10/20 16:03:48 INFO DAGScheduler: Registering RDD 29 (reduceByKey at /home/project2_rdd.py:75) as input to shuffle 2
24/10/20 16:03:48 INFO DAGScheduler: Got job 2 (takeOrdered at /home/project2_rdd.py:80) with 2 output partitions
24/10/20 16:03:48 INFO DAGScheduler: Final stage: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80)
24/10/20 16:03:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
24/10/20 16:03:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
24/10/20 16:03:48 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57), which has no missing parent
s
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost.localdomain:40059 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (PairwiseRDD[14] at reduceByKey at /home/project2_rdd.py:57) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/10/20 16:03:48 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64), which has no missing parent
s
24/10/20 16:03:48 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.1 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost.localdomain:40059 (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (PairwiseRDD[18] at reduceByKey at /home/project2_rdd.py:64) (first 
15 tasks are for partitions Vector(0))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/10/20 16:03:48 INFO PythonRunner: Times: total = 44, boot = -75, init = 119, finish = 0
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1589 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (localhost.localdomain, executor driver, partition 0, PROCESS_LOCAL, 7642 byt
es) 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 62 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/project2_rdd.py:57) finished in 0.068 s
24/10/20 16:03:48 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:48 INFO DAGScheduler: running: Set(ShuffleMapStage 5)
24/10/20 16:03:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:48 INFO DAGScheduler: failed: Set()
24/10/20 16:03:48 INFO BlockManager: Found block rdd_2_0 locally
24/10/20 16:03:48 INFO PythonRunner: Times: total = 47, boot = -5, init = 52, finish = 0
24/10/20 16:03:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1589 bytes result sent to driver
24/10/20 16:03:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 66 ms on localhost.localdomain (executor driver) (1/1)
24/10/20 16:03:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/10/20 16:03:48 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at /home/project2_rdd.py:64) finished in 0.083 s
24/10/20 16:03:48 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:48 INFO DAGScheduler: running: Set()
24/10/20 16:03:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:48 INFO DAGScheduler: failed: Set()
24/10/20 16:03:48 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70), which has no missing parents
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 22.0 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 365.8 MiB)
24/10/20 16:03:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost.localdomain:40059 (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:03:48 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:48 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[25] at join at /home/project2_rdd.py:70) (first 15 task
s are for partitions Vector(0, 1))
24/10/20 16:03:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
24/10/20 16:03:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:03:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:49 INFO PythonRunner: Times: total = 56, boot = -30, init = 86, finish = 0
24/10/20 16:03:49 INFO PythonRunner: Times: total = 94, boot = 11, init = 82, finish = 1
24/10/20 16:03:49 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2235 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7531 bytes)
 
24/10/20 16:03:49 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 151 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:49 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Getting 1 (868.0 B) non-empty blocks including 1 (868.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:49 INFO PythonRunner: Times: total = 60, boot = -84, init = 144, finish = 0
24/10/20 16:03:49 INFO PythonRunner: Times: total = 58, boot = -17, init = 74, finish = 1
24/10/20 16:03:49 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 2235 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 93 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:49 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/10/20 16:03:49 INFO DAGScheduler: ShuffleMapStage 6 (join at /home/project2_rdd.py:70) finished in 0.251 s
24/10/20 16:03:49 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:49 INFO DAGScheduler: running: Set()
24/10/20 16:03:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
24/10/20 16:03:49 INFO DAGScheduler: failed: Set()
24/10/20 16:03:49 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75), which has no missing parent
s
24/10/20 16:03:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 17.2 KiB, free 365.7 MiB)
24/10/20 16:03:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 365.7 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost.localdomain:40059 (size: 9.6 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[29] at reduceByKey at /home/project2_rdd.py:75) (first 
15 tasks are for partitions Vector(0, 1))
24/10/20 16:03:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
24/10/20 16:03:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:03:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Getting 2 (980.0 B) non-empty blocks including 2 (980.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:49 INFO PythonRunner: Times: total = 49, boot = -38, init = 86, finish = 1
24/10/20 16:03:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7422 bytes)
 
24/10/20 16:03:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 79 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:49 INFO Executor: Running task 1.0 in stage 7.0 (TID 9)
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Getting 2 (1245.0 B) non-empty blocks including 2 (1245.0 B) local and 0 (0.0 B) host-local and 0 (0.0 
B) push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:49 INFO PythonRunner: Times: total = 57, boot = -108, init = 164, finish = 1
24/10/20 16:03:49 INFO Executor: Finished task 1.0 in stage 7.0 (TID 9). 2235 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 81 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/10/20 16:03:49 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at /home/project2_rdd.py:75) finished in 0.169 s
24/10/20 16:03:49 INFO DAGScheduler: looking for newly runnable stages
24/10/20 16:03:49 INFO DAGScheduler: running: Set()
24/10/20 16:03:49 INFO DAGScheduler: waiting: Set(ResultStage 8)
24/10/20 16:03:49 INFO DAGScheduler: failed: Set()
24/10/20 16:03:49 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80), which has no missing parents
24/10/20 16:03:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 13.2 KiB, free 365.7 MiB)
24/10/20 16:03:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.7 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost.localdomain:40059 (size: 7.4 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
24/10/20 16:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[32] at takeOrdered at /home/project2_rdd.py:80) (first 15 tas
ks are for partitions Vector(0, 1))
24/10/20 16:03:49 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
24/10/20 16:03:49 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (localhost.localdomain, executor driver, partition 0, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:03:49 INFO Executor: Running task 0.0 in stage 8.0 (TID 10)
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Getting 2 (532.0 B) non-empty blocks including 2 (532.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost.localdomain:40059 in memory (size: 6.0 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO PythonRunner: Times: total = 53, boot = -139, init = 191, finish = 1
24/10/20 16:03:49 INFO Executor: Finished task 0.0 in stage 8.0 (TID 10). 2168 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11) (localhost.localdomain, executor driver, partition 1, NODE_LOCAL, 7433 bytes
) 
24/10/20 16:03:49 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 92 ms on localhost.localdomain (executor driver) (1/2)
24/10/20 16:03:49 INFO Executor: Running task 1.0 in stage 8.0 (TID 11)
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Getting 2 (490.0 B) non-empty blocks including 2 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B)
 push-merged-local and 0 (0.0 B) remote blocks
24/10/20 16:03:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost.localdomain:40059 in memory (size: 8.8 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost.localdomain:40059 in memory (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost.localdomain:40059 in memory (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost.localdomain:40059 in memory (size: 9.7 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost.localdomain:40059 in memory (size: 9.1 KiB, free: 366.2 MiB)
24/10/20 16:03:49 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost.localdomain:40059 in memory (size: 6.0 KiB, free: 366.3 MiB)
24/10/20 16:03:49 INFO PythonRunner: Times: total = 47, boot = -132, init = 179, finish = 0
24/10/20 16:03:49 INFO Executor: Finished task 1.0 in stage 8.0 (TID 11). 2154 bytes result sent to driver
24/10/20 16:03:49 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 58 ms on localhost.localdomain (executor driver) (2/2)
24/10/20 16:03:49 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/10/20 16:03:49 INFO DAGScheduler: ResultStage 8 (takeOrdered at /home/project2_rdd.py:80) finished in 0.173 s
24/10/20 16:03:49 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/10/20 16:03:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/10/20 16:03:49 INFO DAGScheduler: Job 2 finished: takeOrdered at /home/project2_rdd.py:80, took 0.741268 s
Traceback (most recent call last):
  File "/home/project2_rdd.py", line 95, in <module>
    Project2().run(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
  File "/home/project2_rdd.py", line 86, in run
    .coalesce(1).saveAsTextFile(output_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apache-spark/python/lib/pyspark.zip/pyspark/rdd.py", line 3425, in saveAsTextFile
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/apache-spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o187.saveAsTextFile.
: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/output already exists
at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)
at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)
at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)
at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1620)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1620)
at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1606)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1606)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)
at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)
at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
at java.lang.Thread.run(Thread.java:750)

24/10/20 16:03:49 INFO SparkContext: Invoking stop() from shutdown hook
24/10/20 16:03:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/10/20 16:03:49 INFO SparkUI: Stopped Spark web UI at http://localhost.localdomain:4040
24/10/20 16:03:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/10/20 16:03:49 INFO MemoryStore: MemoryStore cleared
24/10/20 16:03:49 INFO BlockManager: BlockManager stopped
24/10/20 16:03:49 INFO BlockManagerMaster: BlockManagerMaster stopped
24/10/20 16:03:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/10/20 16:03:49 INFO SparkContext: Successfully stopped SparkContext
24/10/20 16:03:49 INFO ShutdownHookManager: Shutdown hook called
24/10/20 16:03:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-bfa520a7-a46c-4068-9890-98d2c3e405e7
24/10/20 16:03:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-b16e6290-2e5c-4b49-8437-7e7f348634a8
24/10/20 16:03:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-b16e6290-2e5c-4b49-8437-7e7f348634a8/pyspark-7aa6e93b-58d6-465b-9d33-e4ed974f4334
[user@sahara ~]$ cat/home/output/part-*
bash: cat/home/output/part-*: No such file or directory